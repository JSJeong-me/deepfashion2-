{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled15.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "https://github.com/JSJeong-me/Detectron2/blob/main/aquarium-detectron2.ipynb",
      "authorship_tag": "ABX9TyOelclBZMp6elpPF+g0U8Gc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/deepfashion2-/blob/main/deepfashion-0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuZFJftRmVRW"
      },
      "source": [
        "# https://medium.com/red-buffer/training-an-object-detection-model-in-a-few-minutes-using-detectron2-5bd0aa5550d4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxgMRqXU4fwk"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvJUQDfbbGiB"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVY6xlXbbKlS"
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZRbjuyYbOY6"
      },
      "source": [
        "torch.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5UvOska56NK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "885f037f-b939-4fde-9e88-e2b42b56d059"
      },
      "source": [
        "!pip install pyyaml==5.1\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "assert torch.__version__.startswith(\"1.9\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyyaml==5.1\n",
            "  Downloading PyYAML-5.1.tar.gz (274 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▏                              | 10 kB 34.4 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20 kB 19.3 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30 kB 15.8 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 40 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████                          | 51 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 61 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 71 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 81 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 92 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 102 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 112 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 122 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 133 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 143 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 153 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 163 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 174 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 184 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 194 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 204 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 215 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 225 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 235 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 245 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 256 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 266 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 274 kB 7.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyyaml\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.1-cp37-cp37m-linux_x86_64.whl size=44092 sha256=537e3b8a3e4b5926559fcb0bdc19d3a71910e215e988778917c0d4199752c86f\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/f5/10/d00a2bd30928b972790053b5de0c703ca87324f3fead0f2fd9\n",
            "Successfully built pyyaml\n",
            "Installing collected packages: pyyaml\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed pyyaml-5.1\n",
            "1.9.0+cu111 True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5NDrVwF6IPN"
      },
      "source": [
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu111/torch1.9/index.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsEbTIK8wt77"
      },
      "source": [
        "Restart kernel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPFhBIjGq3pp"
      },
      "source": [
        "Downloading Dataset\n",
        "\n",
        "Data set url -> https://drive.google.com/drive/folders/125F48fsMBz2EF0Cpqk6aaHet5VH399Ok\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yk85DUjFbeIQ"
      },
      "source": [
        "#!mkdir /content/DeepFashion2/\n",
        "!cp /content/drive/MyDrive/deepfashion2/validation.zip /content/DeepFashion2/"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYvudtRr8GBo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b67da67-9a74-4a25-a927-c111b6f0953c"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kslh1MAP7JKP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c788417b-f364-49f0-fd9c-557c6021943a"
      },
      "source": [
        "!ls -l"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 12\n",
            "drwxr-xr-x 2 root root 4096 Nov  2 03:36 DeepFashion2\n",
            "drwx------ 6 root root 4096 Nov  2 03:22 drive\n",
            "drwxr-xr-x 1 root root 4096 Oct 26 13:34 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GU9Xf_06ubBI"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRo72tNmmYfO"
      },
      "source": [
        "!unzip -P \"2019Deepfashion2**\" /content/DeepFashion2/validation.zip -d /content/DeepFashion2/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71PcoVjDvoGg",
        "outputId": "75f39359-6c18-4a73-b1fc-068e9993ff7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls /content/DeepFashion2/validation/image | wc -l\n",
        "!ls /content/DeepFashion2/validation/annos | wc -l"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32153\n",
            "32153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSM6uVFEv22p"
      },
      "source": [
        "DeepFashion2 dataset을 Deepfashion2 github에서 제공하는 deepfashion2_to_coco.py파일 활용해 COCO format으로 변환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cy2EiQ-S_vMh"
      },
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "dataset = {\n",
        "    \"info\": {},\n",
        "    \"licenses\": [],\n",
        "    \"images\": [],\n",
        "    \"annotations\": [],\n",
        "    \"categories\": []\n",
        "}\n",
        "\n",
        "lst_name = ['short_sleeved_shirt', 'long_sleeved_shirt', 'short_sleeved_outwear', 'long_sleeved_outwear',\n",
        "            'vest', 'sling', 'shorts', 'trousers', 'skirt', 'short_sleeved_dress',\n",
        "            'long_sleeved_dress', 'vest_dress', 'sling_dress']\n",
        "\n",
        "for idx, e  in enumerate(lst_name):\n",
        "    dataset['categories'].append({\n",
        "        'id': idx + 1,\n",
        "        'name': e,\n",
        "        'supercategory': \"clothes\",\n",
        "        'keypoints': ['%i' % (i) for i in range(1, 295)],\n",
        "        'skeleton': []\n",
        "    })\n",
        "\n",
        "num_images = 32153 #191961 \n",
        "sub_index = 0  # the index of ground truth instance\n",
        "for num in range(1, num_images + 1):\n",
        "    json_name = '/content/DeepFashion2/validation/annos/' + str(num).zfill(6) + '.json'\n",
        "    image_name = '/content/DeepFashion2/validation/image/' + str(num).zfill(6) + '.jpg'\n",
        "\n",
        "    if (num >= 0):\n",
        "        imag = Image.open(image_name)\n",
        "        width, height = imag.size\n",
        "        with open(json_name, 'r') as f:\n",
        "            temp = json.loads(f.read())\n",
        "            pair_id = temp['pair_id']\n",
        "\n",
        "            dataset['images'].append({\n",
        "                'coco_url': '',\n",
        "                'date_captured': '',\n",
        "                'file_name': str(num).zfill(6) + '.jpg',\n",
        "                'flickr_url': '',\n",
        "                'id': num,\n",
        "                'license': 0,\n",
        "                'width': width,\n",
        "                'height': height\n",
        "            })\n",
        "            for i in temp:\n",
        "                if i == 'source' or i == 'pair_id':\n",
        "                    continue\n",
        "                else:\n",
        "                    points = np.zeros(294 * 3)\n",
        "                    sub_index = sub_index + 1\n",
        "                    box = temp[i]['bounding_box']\n",
        "                    w = box[2] - box[0]\n",
        "                    h = box[3] - box[1]\n",
        "                    x_1 = box[0]\n",
        "                    y_1 = box[1]\n",
        "                    bbox = [x_1, y_1, w, h]\n",
        "                    cat = temp[i]['category_id']\n",
        "                    style = temp[i]['style']\n",
        "                    seg = temp[i]['segmentation']\n",
        "                    landmarks = temp[i]['landmarks']\n",
        "\n",
        "                    points_x = landmarks[0::3]\n",
        "                    points_y = landmarks[1::3]\n",
        "                    points_v = landmarks[2::3]\n",
        "                    points_x = np.array(points_x)\n",
        "                    points_y = np.array(points_y)\n",
        "                    points_v = np.array(points_v)\n",
        "                    case = [0, 25, 58, 89, 128, 143, 158, 168, 182, 190, 219, 256, 275, 294]\n",
        "                    idx_i, idx_j = case[cat - 1], case[cat]\n",
        "\n",
        "                    for n in range(idx_i, idx_j):\n",
        "                        points[3 * n] = points_x[n - idx_i]\n",
        "                        points[3 * n + 1] = points_y[n - idx_i]\n",
        "                        points[3 * n + 2] = points_v[n - idx_i]\n",
        "\n",
        "                    num_points = len(np.where(points_v > 0)[0])\n",
        "\n",
        "                    dataset['annotations'].append({\n",
        "                        'area': w * h,\n",
        "                        'bbox': bbox,\n",
        "                        'category_id': cat,\n",
        "                        'id': sub_index,\n",
        "                        'pair_id': pair_id,\n",
        "                        'image_id': num,\n",
        "                        'iscrowd': 0,\n",
        "                        'style': style,\n",
        "                        'num_keypoints': num_points,\n",
        "                        'keypoints': points.tolist(),\n",
        "                        'segmentation': seg,\n",
        "                    })\n",
        "\n",
        "json_name = '/content/deepfashion2_validation.json'\n",
        "with open(json_name, 'w') as f:\n",
        "    json.dump(dataset, f)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHPt1Z68wHw3"
      },
      "source": [
        "Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFhCSNQmwPOv"
      },
      "source": [
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruOV6b-Ww-xg"
      },
      "source": [
        "from detectron2.data.datasets import register_coco_instances\n",
        "#register_coco_instances(\"deepfashion_train\", {}, \"/content/DeepFashion2/deepfashion2_train.json\", \"/content/DeepFashion2/train/image\")\n",
        "\n",
        "register_coco_instances(\"deepfashion_val\", {}, \"/content/DeepFashion2/deepfashion2_validation.json\", \"/content/DeepFashion2/validation/image\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cy19Ma2KmYZM"
      },
      "source": [
        "#from detectron2.data import MetadataCatalog\n",
        "\n",
        "#MetadataCatalog.get('aquarium_train').thing_classes = ['creatures', 'fish', 'jellyfish', 'penguin', 'puffin', 'shark', 'starfish', 'stingray']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9PI3FDMx0tP"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuBgw4HOxn2W",
        "outputId": "c4c247ff-f15b-4a9f-ceb0-89c2be9a9704",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cfg = get_cfg()\n",
        "\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"deepfashion_val\",)\n",
        "cfg.DATASETS.TEST = ()\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
        "\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg.SOLVER.BASE_LR = 0.00125\n",
        "cfg.SOLVER.WARMUP_ITERS = 1000\n",
        "cfg.SOLVER.MAX_ITER = 1500\n",
        "cfg.SOLVER.STEPS = []\n",
        "cfg.SOLVER.GAMMA = 0.05\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 13\n",
        "\n",
        "cfg.TEST.EVAL_PERIOD = 500\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = DefaultTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[11/02 04:01:24 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (6): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (7): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (8): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (9): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (10): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (11): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (12): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (13): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (14): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (15): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (16): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (17): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (18): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (19): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (20): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (21): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (22): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=14, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=52, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[11/02 04:01:37 d2.data.datasets.coco]: \u001b[0mLoading /content/DeepFashion2/deepfashion2_validation.json takes 12.40 seconds.\n",
            "\u001b[32m[11/02 04:01:37 d2.data.datasets.coco]: \u001b[0mLoaded 32153 images in COCO format from /content/DeepFashion2/deepfashion2_validation.json\n",
            "\u001b[32m[11/02 04:01:45 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 32153 images left.\n",
            "\u001b[32m[11/02 04:01:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[11/02 04:01:46 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "\u001b[32m[11/02 04:01:46 d2.data.common]: \u001b[0mSerializing 32153 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[11/02 04:01:48 d2.data.common]: \u001b[0mSerialized dataset takes 490.80 MiB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "model_final_f6e8b1.pkl: 243MB [00:02, 95.3MB/s]                          \n",
            "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (14, 1024) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (14,) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (52, 1024) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (52,) in the model! You might want to double check if this is expected.\n",
            "Some model parameters or buffers are not found in the checkpoint:\n",
            "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
            "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[11/02 04:01:56 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
            "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
            "  return torch.floor_divide(self, other)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[11/02 04:02:04 d2.utils.events]: \u001b[0m eta: 0:08:35  iter: 19  total_loss: 3.699  loss_cls: 2.734  loss_box_reg: 0.9468  loss_rpn_cls: 0.02164  loss_rpn_loc: 0.01761  time: 0.3475  data_time: 0.0172  lr: 2.4976e-05  max_mem: 3532M\n",
            "\u001b[32m[11/02 04:02:12 d2.utils.events]: \u001b[0m eta: 0:08:53  iter: 39  total_loss: 3.143  loss_cls: 2.257  loss_box_reg: 0.897  loss_rpn_cls: 0.03165  loss_rpn_loc: 0.01828  time: 0.3684  data_time: 0.0046  lr: 4.9951e-05  max_mem: 3899M\n",
            "\u001b[32m[11/02 04:02:19 d2.utils.events]: \u001b[0m eta: 0:08:45  iter: 59  total_loss: 2.3  loss_cls: 1.303  loss_box_reg: 0.9349  loss_rpn_cls: 0.01635  loss_rpn_loc: 0.01764  time: 0.3668  data_time: 0.0047  lr: 7.4926e-05  max_mem: 3899M\n",
            "\u001b[32m[11/02 04:02:26 d2.utils.events]: \u001b[0m eta: 0:08:35  iter: 79  total_loss: 1.989  loss_cls: 0.9976  loss_box_reg: 0.968  loss_rpn_cls: 0.01418  loss_rpn_loc: 0.01559  time: 0.3623  data_time: 0.0046  lr: 9.9901e-05  max_mem: 3899M\n",
            "\u001b[32m[11/02 04:02:33 d2.utils.events]: \u001b[0m eta: 0:08:28  iter: 99  total_loss: 1.814  loss_cls: 0.9078  loss_box_reg: 0.8629  loss_rpn_cls: 0.01085  loss_rpn_loc: 0.01441  time: 0.3639  data_time: 0.0048  lr: 0.00012488  max_mem: 4019M\n",
            "\u001b[32m[11/02 04:02:40 d2.utils.events]: \u001b[0m eta: 0:08:10  iter: 119  total_loss: 1.784  loss_cls: 0.8657  loss_box_reg: 0.8876  loss_rpn_cls: 0.009987  loss_rpn_loc: 0.0112  time: 0.3595  data_time: 0.0048  lr: 0.00014985  max_mem: 4019M\n",
            "\u001b[32m[11/02 04:02:47 d2.utils.events]: \u001b[0m eta: 0:08:03  iter: 139  total_loss: 1.813  loss_cls: 0.8488  loss_box_reg: 0.9261  loss_rpn_cls: 0.004066  loss_rpn_loc: 0.01103  time: 0.3610  data_time: 0.0044  lr: 0.00017483  max_mem: 4019M\n",
            "\u001b[32m[11/02 04:02:55 d2.utils.events]: \u001b[0m eta: 0:07:56  iter: 159  total_loss: 1.666  loss_cls: 0.7598  loss_box_reg: 0.8881  loss_rpn_cls: 0.004211  loss_rpn_loc: 0.009458  time: 0.3599  data_time: 0.0048  lr: 0.0001998  max_mem: 4019M\n",
            "\u001b[32m[11/02 04:03:02 d2.utils.events]: \u001b[0m eta: 0:07:49  iter: 179  total_loss: 1.64  loss_cls: 0.7411  loss_box_reg: 0.8877  loss_rpn_cls: 0.002494  loss_rpn_loc: 0.01088  time: 0.3589  data_time: 0.0047  lr: 0.00022478  max_mem: 4019M\n",
            "\u001b[32m[11/02 04:03:09 d2.utils.events]: \u001b[0m eta: 0:07:41  iter: 199  total_loss: 1.658  loss_cls: 0.7763  loss_box_reg: 0.8562  loss_rpn_cls: 0.008507  loss_rpn_loc: 0.01038  time: 0.3601  data_time: 0.0044  lr: 0.00024975  max_mem: 4019M\n",
            "\u001b[32m[11/02 04:03:16 d2.utils.events]: \u001b[0m eta: 0:07:35  iter: 219  total_loss: 1.506  loss_cls: 0.6928  loss_box_reg: 0.7936  loss_rpn_cls: 0.004396  loss_rpn_loc: 0.01063  time: 0.3612  data_time: 0.0046  lr: 0.00027473  max_mem: 4019M\n",
            "\u001b[32m[11/02 04:03:24 d2.utils.events]: \u001b[0m eta: 0:07:28  iter: 239  total_loss: 1.626  loss_cls: 0.7113  loss_box_reg: 0.8846  loss_rpn_cls: 0.002297  loss_rpn_loc: 0.01058  time: 0.3616  data_time: 0.0046  lr: 0.0002997  max_mem: 4019M\n",
            "\u001b[32m[11/02 04:03:31 d2.utils.events]: \u001b[0m eta: 0:07:20  iter: 259  total_loss: 1.657  loss_cls: 0.7294  loss_box_reg: 0.9044  loss_rpn_cls: 0.005895  loss_rpn_loc: 0.009407  time: 0.3606  data_time: 0.0046  lr: 0.00032468  max_mem: 4019M\n",
            "\u001b[32m[11/02 04:03:38 d2.utils.events]: \u001b[0m eta: 0:07:13  iter: 279  total_loss: 1.51  loss_cls: 0.6367  loss_box_reg: 0.8452  loss_rpn_cls: 0.002763  loss_rpn_loc: 0.01167  time: 0.3612  data_time: 0.0046  lr: 0.00034965  max_mem: 4019M\n",
            "\u001b[32m[11/02 04:03:46 d2.utils.events]: \u001b[0m eta: 0:07:07  iter: 299  total_loss: 1.452  loss_cls: 0.6467  loss_box_reg: 0.7986  loss_rpn_cls: 0.0006421  loss_rpn_loc: 0.007583  time: 0.3631  data_time: 0.0048  lr: 0.00037463  max_mem: 4019M\n",
            "\u001b[32m[11/02 04:03:53 d2.utils.events]: \u001b[0m eta: 0:06:59  iter: 319  total_loss: 1.437  loss_cls: 0.6393  loss_box_reg: 0.7881  loss_rpn_cls: 0.003531  loss_rpn_loc: 0.01257  time: 0.3627  data_time: 0.0051  lr: 0.0003996  max_mem: 4019M\n",
            "\u001b[32m[11/02 04:04:00 d2.utils.events]: \u001b[0m eta: 0:06:52  iter: 339  total_loss: 1.369  loss_cls: 0.6758  loss_box_reg: 0.7285  loss_rpn_cls: 0.001863  loss_rpn_loc: 0.009561  time: 0.3616  data_time: 0.0048  lr: 0.00042458  max_mem: 4019M\n",
            "\u001b[32m[11/02 04:04:07 d2.utils.events]: \u001b[0m eta: 0:06:45  iter: 359  total_loss: 1.343  loss_cls: 0.6124  loss_box_reg: 0.6991  loss_rpn_cls: 0.005022  loss_rpn_loc: 0.01464  time: 0.3621  data_time: 0.0047  lr: 0.00044955  max_mem: 4019M\n",
            "\u001b[32m[11/02 04:04:15 d2.utils.events]: \u001b[0m eta: 0:06:38  iter: 379  total_loss: 1.291  loss_cls: 0.6079  loss_box_reg: 0.5998  loss_rpn_cls: 0.003793  loss_rpn_loc: 0.01137  time: 0.3622  data_time: 0.0045  lr: 0.00047453  max_mem: 4019M\n",
            "\u001b[32m[11/02 04:04:22 d2.utils.events]: \u001b[0m eta: 0:06:31  iter: 399  total_loss: 1.227  loss_cls: 0.5895  loss_box_reg: 0.6057  loss_rpn_cls: 0.00151  loss_rpn_loc: 0.009042  time: 0.3620  data_time: 0.0047  lr: 0.0004995  max_mem: 4019M\n",
            "\u001b[32m[11/02 04:04:29 d2.utils.events]: \u001b[0m eta: 0:06:24  iter: 419  total_loss: 1.259  loss_cls: 0.6391  loss_box_reg: 0.5931  loss_rpn_cls: 0.001829  loss_rpn_loc: 0.01144  time: 0.3627  data_time: 0.0051  lr: 0.00052448  max_mem: 4019M\n",
            "\u001b[32m[11/02 04:04:36 d2.utils.events]: \u001b[0m eta: 0:06:17  iter: 439  total_loss: 1.312  loss_cls: 0.6471  loss_box_reg: 0.6558  loss_rpn_cls: 0.001887  loss_rpn_loc: 0.01091  time: 0.3617  data_time: 0.0048  lr: 0.00054945  max_mem: 4019M\n",
            "\u001b[32m[11/02 04:04:44 d2.utils.events]: \u001b[0m eta: 0:06:10  iter: 459  total_loss: 1.136  loss_cls: 0.5261  loss_box_reg: 0.5757  loss_rpn_cls: 0.002761  loss_rpn_loc: 0.009978  time: 0.3621  data_time: 0.0046  lr: 0.00057443  max_mem: 4019M\n",
            "\u001b[32m[11/02 04:04:51 d2.utils.events]: \u001b[0m eta: 0:06:02  iter: 479  total_loss: 1.078  loss_cls: 0.5311  loss_box_reg: 0.4913  loss_rpn_cls: 0.001629  loss_rpn_loc: 0.009353  time: 0.3614  data_time: 0.0047  lr: 0.0005994  max_mem: 4019M\n",
            "\u001b[32m[11/02 04:04:58 d2.utils.events]: \u001b[0m eta: 0:05:55  iter: 499  total_loss: 1.119  loss_cls: 0.5807  loss_box_reg: 0.498  loss_rpn_cls: 0.003758  loss_rpn_loc: 0.00985  time: 0.3610  data_time: 0.0052  lr: 0.00062438  max_mem: 4019M\n",
            "\u001b[32m[11/02 04:05:05 d2.utils.events]: \u001b[0m eta: 0:05:48  iter: 519  total_loss: 1.108  loss_cls: 0.6105  loss_box_reg: 0.4972  loss_rpn_cls: 0.001314  loss_rpn_loc: 0.01017  time: 0.3609  data_time: 0.0045  lr: 0.00064935  max_mem: 4019M\n",
            "\u001b[32m[11/02 04:05:12 d2.utils.events]: \u001b[0m eta: 0:05:41  iter: 539  total_loss: 0.9489  loss_cls: 0.5229  loss_box_reg: 0.4466  loss_rpn_cls: 0.001622  loss_rpn_loc: 0.01153  time: 0.3603  data_time: 0.0044  lr: 0.00067433  max_mem: 4019M\n",
            "\u001b[32m[11/02 04:05:19 d2.utils.events]: \u001b[0m eta: 0:05:34  iter: 559  total_loss: 0.972  loss_cls: 0.5485  loss_box_reg: 0.4924  loss_rpn_cls: 0.0007011  loss_rpn_loc: 0.008461  time: 0.3608  data_time: 0.0046  lr: 0.0006993  max_mem: 4019M\n",
            "\u001b[32m[11/02 04:05:26 d2.utils.events]: \u001b[0m eta: 0:05:27  iter: 579  total_loss: 0.9506  loss_cls: 0.5089  loss_box_reg: 0.4281  loss_rpn_cls: 0.002218  loss_rpn_loc: 0.009223  time: 0.3608  data_time: 0.0054  lr: 0.00072428  max_mem: 4019M\n",
            "\u001b[32m[11/02 04:05:34 d2.utils.events]: \u001b[0m eta: 0:05:20  iter: 599  total_loss: 0.954  loss_cls: 0.5238  loss_box_reg: 0.4666  loss_rpn_cls: 0.002599  loss_rpn_loc: 0.006349  time: 0.3606  data_time: 0.0048  lr: 0.00074925  max_mem: 4019M\n",
            "\u001b[32m[11/02 04:05:41 d2.utils.events]: \u001b[0m eta: 0:05:13  iter: 619  total_loss: 0.9224  loss_cls: 0.4438  loss_box_reg: 0.4716  loss_rpn_cls: 0.0009397  loss_rpn_loc: 0.006957  time: 0.3608  data_time: 0.0048  lr: 0.00077423  max_mem: 4019M\n",
            "\u001b[32m[11/02 04:05:48 d2.utils.events]: \u001b[0m eta: 0:05:06  iter: 639  total_loss: 0.988  loss_cls: 0.5595  loss_box_reg: 0.4601  loss_rpn_cls: 0.001035  loss_rpn_loc: 0.00841  time: 0.3612  data_time: 0.0049  lr: 0.0007992  max_mem: 4019M\n",
            "\u001b[32m[11/02 04:05:56 d2.utils.events]: \u001b[0m eta: 0:04:59  iter: 659  total_loss: 0.8671  loss_cls: 0.4694  loss_box_reg: 0.3752  loss_rpn_cls: 0.001157  loss_rpn_loc: 0.01075  time: 0.3618  data_time: 0.0045  lr: 0.00082418  max_mem: 4019M\n",
            "\u001b[32m[11/02 04:06:03 d2.utils.events]: \u001b[0m eta: 0:04:52  iter: 679  total_loss: 0.9402  loss_cls: 0.4755  loss_box_reg: 0.4307  loss_rpn_cls: 0.0007844  loss_rpn_loc: 0.008609  time: 0.3614  data_time: 0.0046  lr: 0.00084915  max_mem: 4019M\n",
            "\u001b[32m[11/02 04:06:11 d2.utils.events]: \u001b[0m eta: 0:04:45  iter: 699  total_loss: 1.006  loss_cls: 0.4819  loss_box_reg: 0.4483  loss_rpn_cls: 0.0004293  loss_rpn_loc: 0.007627  time: 0.3618  data_time: 0.0047  lr: 0.00087413  max_mem: 4019M\n",
            "\u001b[32m[11/02 04:06:18 d2.utils.events]: \u001b[0m eta: 0:04:37  iter: 719  total_loss: 1.011  loss_cls: 0.5309  loss_box_reg: 0.4414  loss_rpn_cls: 0.001227  loss_rpn_loc: 0.008232  time: 0.3619  data_time: 0.0048  lr: 0.0008991  max_mem: 4019M\n",
            "\u001b[32m[11/02 04:06:25 d2.utils.events]: \u001b[0m eta: 0:04:30  iter: 739  total_loss: 0.7799  loss_cls: 0.4211  loss_box_reg: 0.3581  loss_rpn_cls: 0.0002585  loss_rpn_loc: 0.007584  time: 0.3620  data_time: 0.0047  lr: 0.00092408  max_mem: 4019M\n",
            "\u001b[32m[11/02 04:06:33 d2.utils.events]: \u001b[0m eta: 0:04:23  iter: 759  total_loss: 0.8359  loss_cls: 0.4227  loss_box_reg: 0.3982  loss_rpn_cls: 0.000476  loss_rpn_loc: 0.00615  time: 0.3622  data_time: 0.0050  lr: 0.00094905  max_mem: 4019M\n",
            "\u001b[32m[11/02 04:06:40 d2.utils.events]: \u001b[0m eta: 0:04:16  iter: 779  total_loss: 0.9275  loss_cls: 0.4722  loss_box_reg: 0.3962  loss_rpn_cls: 0.0008812  loss_rpn_loc: 0.00898  time: 0.3619  data_time: 0.0050  lr: 0.00097403  max_mem: 4019M\n",
            "\u001b[32m[11/02 04:06:47 d2.utils.events]: \u001b[0m eta: 0:04:09  iter: 799  total_loss: 1.12  loss_cls: 0.5147  loss_box_reg: 0.5424  loss_rpn_cls: 0.001344  loss_rpn_loc: 0.008789  time: 0.3624  data_time: 0.0048  lr: 0.000999  max_mem: 4019M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBOpqEKX8Q1C"
      },
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-KF0fo5mz59"
      },
      "source": [
        "Inference and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQ6b57tyGykp"
      },
      "source": [
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciYRRJSF0hT6"
      },
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n",
        "cfg.DATASETS.TEST = (\"deepfashion_val\", )\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYA4AG9Z0jP1"
      },
      "source": [
        "!wget https://img-lcwaikiki.mncdn.com/mnresize/1024/-//productimages/20201/1/3945185/l_20201-0sg016z8-cs8_a.jpg -O /content/example.jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJEtV6x70sQd"
      },
      "source": [
        "from detectron2.utils.visualizer import ColorMode\n",
        "im = cv2.imread(\"/content/example.jpg\")\n",
        "outputs = predictor(im)\n",
        "# We can use `Visualizer` to draw the predictions on the image.\n",
        "v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
        "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "cv2_imshow(v.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSmxtiMd0v_2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VghPZX7tm7ow"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVypdztOmYQ0"
      },
      "source": [
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "evaluator = COCOEvaluator(\"aquarium_val\", cfg, False, output_dir=\"./output/\")\n",
        "val_loader = build_detection_test_loader(cfg, \"aquarium_val\")\n",
        "print(inference_on_dataset(trainer.model, val_loader, evaluator))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxEWg61CnHKw"
      },
      "source": [
        "Saving and reloading the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eITlgyi0mYNg"
      },
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVOFtPtymYJq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7N114yAZnPbL"
      },
      "source": [
        "Saving and reloading the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4Pfij7UmX6h"
      },
      "source": [
        "import torch\n",
        "new_cfg = get_cfg()\n",
        "new_cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
        "new_cfg.MODEL.ROI_HEADS.NUM_CLASSES = 8\n",
        "new_cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n",
        "new_cfg.MODEL.WEIGHTS = \"./output/model_final.pth\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gh7lxD2Is7w"
      },
      "source": [
        "im = cv2.imread('/content/test/IMG_2514_jpeg_jpg.rf.19de1787caef21dba070ac1b1c78e5e0.jpg')\n",
        "outputs = predictor(im)\n",
        "\n",
        "\n",
        "v = Visualizer(im[:, :, ::-1],\n",
        "metadata=MetadataCatalog.get('aquarium_train'),\n",
        "scale=2,\n",
        "instance_mode=ColorMode.IMAGE_BW)\n",
        "out = v.draw_instance_predictions(outputs['instances'].to(\"cpu\"))\n",
        "cv2_imshow(out.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1BseG4di6jm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}